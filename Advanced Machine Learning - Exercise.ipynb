{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T02:09:43.196177Z",
     "start_time": "2019-11-08T02:09:43.183426Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:12:02.100150Z",
     "start_time": "2019-11-08T04:12:02.084830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset (iris), split into X_train, y_train, X_test, y_test!\n",
    "# Write your code here \n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T02:57:33.466206Z",
     "start_time": "2019-11-08T02:57:33.442382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hint: \n",
    "# clf_voting = VotingClassifier(estimators=[('label1', clf_1), ('label2', clf_2), ('labelN', clf_N)]) \n",
    "\n",
    "# Create the individual models\n",
    "clf_knn = KNeighborsClassifier(5)\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# Create voting classifier\n",
    "clf_voting = VotingClassifier(estimators=[('knn', clf_knn),\n",
    "                                            ('dt', clf_dt),\n",
    "                                            ('lr', clf_lr)])\n",
    "\n",
    "# Fit it to the training set and predict\n",
    "clf_voting.fit(X_train, y_train)\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T02:57:34.247814Z",
     "start_time": "2019-11-08T02:57:34.222184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of the KNN model\n",
    "import sklearn.metrics as metrics\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy KNN: {:0.3f}\".format(acc_knn))\n",
    "print(metrics.classification_report(y_test, clf_knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:21:25.141945Z",
     "start_time": "2019-11-08T04:21:25.121280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of decision tree: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of the Decision Tree model\n",
    "import sklearn.metrics as metrics\n",
    "clf_dt.fit(X_train, y_train)\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy of decision tree: {:0.3f}\".format(acc_dt))\n",
    "print(metrics.classification_report(y_test, clf_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:21:20.254091Z",
     "start_time": "2019-11-08T04:21:20.234197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.93      0.91      0.91        45\n",
      "weighted avg       0.93      0.91      0.91        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of the Logistic Regression model\n",
    "import sklearn.metrics as metrics\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc_lr))\n",
    "print(metrics.classification_report(y_test, clf_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Averaging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T02:57:40.241957Z",
     "start_time": "2019-11-08T02:57:40.233734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Template for averaging Classifier \n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# clf_voting = VotingClassifier(\n",
    "# estimators=[\n",
    "#('label1', clf_1),\n",
    "#('label2', clf_2),\n",
    "#...\n",
    "#('labelN', clf_N)],\n",
    "#voting='soft',\n",
    "#weights=[w_1, w_2, ..., w_N]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:21:10.525415Z",
     "start_time": "2019-11-08T04:21:10.495328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of averaging method: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.93      0.93      0.93        15\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initiate the individual models \n",
    "\n",
    "# Write your code here! \n",
    "clf_knn = KNeighborsClassifier(5)\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# Create averaging classifier\n",
    "\n",
    "# Write your code here! \n",
    "clf_averaging = VotingClassifier(estimators=[\n",
    "                                ('knn', clf_knn),\n",
    "                                ('dt', clf_dt),\n",
    "                                ('lr', clf_lr)],\n",
    "                                voting='soft',\n",
    "                                weights=[2, 1, 2]\n",
    "                                )\n",
    "\n",
    "clf_averaging.fit(X_train, y_train)\n",
    "y_pred_avg = clf_averaging.predict(X_test)\n",
    "\n",
    "acc_avg = accuracy_score(y_test, y_pred_avg)\n",
    "print(\"Accuracy of averaging method: {:0.3f}\".format(acc_avg))\n",
    "print(metrics.classification_report(y_test, clf_averaging.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:21:01.222525Z",
     "start_time": "2019-11-08T04:21:01.163032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bagging method: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.87        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(3),\n",
    "                           max_samples=0.5, max_features=0.5)\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bag = bagging.predict(X_test)\n",
    "\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "print(\"Accuracy of bagging method: {:0.3f}\".format(acc_bag))\n",
    "print(metrics.classification_report(y_test, bagging.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:20:54.357432Z",
     "start_time": "2019-11-08T04:20:54.304471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bagging method: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.87        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here if base classifier = decision tree!\n",
    "bagging_dt = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           max_samples=0.5, max_features=0.5)\n",
    "\n",
    "bagging_dt.fit(X_train, y_train)\n",
    "y_pred_bagdt = bagging_dt.predict(X_test)\n",
    "\n",
    "acc_bagdt = accuracy_score(y_test, y_pred_bagdt)\n",
    "print(\"Accuracy of bagging method: {:0.3f}\".format(acc_bagdt))\n",
    "print(metrics.classification_report(y_test, bagging_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T06:08:06.124194Z",
     "start_time": "2019-11-08T06:08:04.506552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest method: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.87        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here if you use RandomForest, compare with above!\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = BaggingClassifier(RandomForestClassifier(n_estimators=100),\n",
    "                           max_samples=0.5, max_features=0.5)\n",
    "\n",
    "randomforest.fit(X_train, y_train)\n",
    "y_pred_rf = randomforest.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy of random forest method: {:0.3f}\".format(acc_rf))\n",
    "print(metrics.classification_report(y_test, randomforest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging using German credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:16:49.570877Z",
     "start_time": "2019-11-08T04:16:49.543393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging using German credit data\n",
    "\n",
    "bc_data = datasets.load_breast_cancer()\n",
    "X_bc = bc_data.data\n",
    "y_bc = bc_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:27:44.921812Z",
     "start_time": "2019-11-08T04:27:44.530409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_data_df = pd.DataFrame(bc_data.data, columns=bc_data.feature_names)\n",
    "bc_data_df['target'] = pd.Series(y_bc)\n",
    "bc_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:22:31.162323Z",
     "start_time": "2019-11-08T04:22:31.156519Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(X_bc, y_bc, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:24:14.828080Z",
     "start_time": "2019-11-08T04:24:14.740676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bagging decision tree method: 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        63\n",
      "           1       0.97      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_bc = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           max_samples=0.5, max_features=0.5, random_state=1)\n",
    "\n",
    "bagging_bc.fit(X_train_bc, y_train_bc)\n",
    "y_pred_bagbc = bagging_bc.predict(X_test_bc)\n",
    "\n",
    "acc_bagbc = accuracy_score(y_test_bc, y_pred_bagbc)\n",
    "print(\"Accuracy of bagging decision tree method: {:0.3f}\".format(acc_bagbc))\n",
    "print(metrics.classification_report(y_test_bc, bagging_bc.predict(X_test_bc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:30:49.811307Z",
     "start_time": "2019-11-08T04:30:49.722637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bagging K-Nearest Neighbors method: 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        63\n",
      "           1       0.94      0.99      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_bcknn = BaggingClassifier(KNeighborsClassifier(5),\n",
    "                           max_samples=0.5, max_features=0.5, random_state=1)\n",
    "\n",
    "bagging_bcknn.fit(X_train_bc, y_train_bc)\n",
    "y_pred_bagbcknn = bagging_bcknn.predict(X_test_bc)\n",
    "\n",
    "acc_bagbcknn = accuracy_score(y_test_bc, y_pred_bagbcknn)\n",
    "print(\"Accuracy of bagging K-Nearest Neighbors method: {:0.3f}\".format(acc_bagbcknn))\n",
    "print(metrics.classification_report(y_test_bc, bagging_bcknn.predict(X_test_bc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T04:33:09.120884Z",
     "start_time": "2019-11-08T04:33:08.692376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bagging random forest method: 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        63\n",
      "           1       0.96      0.99      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_bcrf = BaggingClassifier(RandomForestClassifier(n_estimators=20),\n",
    "                           max_samples=0.5, max_features=0.5, random_state=1)\n",
    "\n",
    "bagging_bcrf.fit(X_train_bc, y_train_bc)\n",
    "y_pred_bagbcrf = bagging_bcrf.predict(X_test_bc)\n",
    "\n",
    "acc_bagbcrf = accuracy_score(y_test_bc, y_pred_bagbcrf)\n",
    "print(\"Accuracy of bagging random forest method: {:0.3f}\".format(acc_bagbcrf))\n",
    "print(metrics.classification_report(y_test_bc, bagging_bcrf.predict(X_test_bc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boosting\n",
    "Source: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T06:29:45.551508Z",
     "start_time": "2019-11-08T06:29:45.543363Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T07:05:14.402174Z",
     "start_time": "2019-11-08T07:05:14.369868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost method: 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        63\n",
      "           1       0.96      0.94      0.95       108\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_ada = AdaBoostClassifier(\n",
    "base_estimator=DecisionTreeClassifier(),\n",
    "n_estimators=50,\n",
    "learning_rate=0.11,\n",
    "random_state=1\n",
    ")\n",
    "\n",
    "# base_estimator\n",
    "# Default: Decision Tree (max_depth=1)\n",
    "# n_estimators\n",
    "# Default: 50\n",
    "# learning_rate\n",
    "# Default: 1.0\n",
    "# Trade-off between n_estimators and\n",
    "# learning_rate\n",
    "\n",
    "clf_ada.fit(X_train_bc, y_train_bc)\n",
    "y_pred_ada= clf_ada.predict(X_test_bc)\n",
    "\n",
    "acc_ada = accuracy_score(y_test_bc, y_pred_ada)\n",
    "print(\"Accuracy of AdaBoost method: {:0.3f}\".format(acc_ada))\n",
    "print(metrics.classification_report(y_test_bc, clf_ada.predict(X_test_bc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AdaBoost Classifier for iris dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T06:56:17.818856Z",
     "start_time": "2019-11-08T06:56:17.787208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset_dia = datasets.load_diabetes()\n",
    "\n",
    "X_dia = dataset_dia.data\n",
    "y_dia = dataset_dia.target\n",
    "\n",
    "X_train_dia, X_test_dia, y_train_dia, y_test_dia = train_test_split(X_dia, y_dia, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T07:10:56.805764Z",
     "start_time": "2019-11-08T07:10:53.276711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score using AdaBoost method is 0.199\n",
      "The mean square error using AdaBoost method is 4322.925\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "reg_ada = AdaBoostRegressor(\n",
    "LogisticRegression(),\n",
    "n_estimators=50,\n",
    "learning_rate=0.5,\n",
    "loss='square',\n",
    "random_state=1\n",
    ")\n",
    "\n",
    "# base_estimator\n",
    "# Default: Decision Tree (max_depth=3)\n",
    "# loss\n",
    "# linear (default)\n",
    "# square\n",
    "# exponential\n",
    "\n",
    "\n",
    "reg_ada.fit(X_train_dia, y_train_dia)\n",
    "y_pred_regada= reg_ada.predict(X_test_dia)\n",
    "\n",
    "# acc_regada = accuracy_score(y_test_dia, y_pred_regada)\n",
    "# print(\"Accuracy of AdaBoost method: {:0.3f}\".format(acc_regada))\n",
    "# print(metrics.classification_report(y_test_dia, reg_ada.predict(X_test_dia)))\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print('The r2 score using AdaBoost method is {:0.3f}'.format(r2_score(y_test_dia, y_pred_regada)))\n",
    "print('The mean square error using AdaBoost method is {:0.3f}'.format(mean_squared_error(y_test_dia, y_pred_regada)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GradientBoostingClassifier for iris Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T07:53:46.332635Z",
     "start_time": "2019-11-08T07:53:45.592984Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "# Cek di sini: \n",
    "# https://stackoverflow.com/questions/35139108/how-to-install-xgboost-in-anaconda-python-windows-platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create XGBoost, lightgbm, catboost for iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T07:59:03.713715Z",
     "start_time": "2019-11-08T07:59:03.679076Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T08:32:23.731865Z",
     "start_time": "2019-11-08T08:32:23.496962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking method: 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        63\n",
      "           1       0.97      1.00      0.99       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.99      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the 1st-layer classifiers\n",
    "clf_knn = KNeighborsClassifier(4)\n",
    "clf_dt = DecisionTreeClassifier(random_state=1)\n",
    "clf_rf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "# Instantiate the 2nd-layer classifier\n",
    "clf_lr = LogisticRegression(random_state=1)\n",
    "\n",
    "# Build the Stacking classifier\n",
    "clf_stack = StackingClassifier(\n",
    "classifiers=[clf_knn, clf_dt, clf_rf],\n",
    "meta_classifier=clf_lr,\n",
    "use_probas=False,\n",
    "use_features_in_secondary=False)\n",
    "\n",
    "# Use the fit and predict methods\n",
    "# like with scikit-learn estimators\n",
    "clf_stack.fit(X_train_bc, y_train_bc)\n",
    "y_pred_stack = clf_stack.predict(X_test_bc)\n",
    "\n",
    "acc_stack = accuracy_score(y_test_bc, y_pred_stack)\n",
    "print(\"Accuracy of Stacking method: {:0.3f}\".format(acc_stack))\n",
    "print(metrics.classification_report(y_test_bc, clf_stack.predict(X_test_bc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
